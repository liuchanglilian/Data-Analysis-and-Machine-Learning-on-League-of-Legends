{"cells":[{"cell_type":"code","source":["Dataset Review\nThe dataset we are going to use is publicly released by kaggle about LOL professional games. This data derives from census data, and consists of information about 3801 matches and their other information in each match. We will use this information to predict if an team win a game or not. The dataset is rather clean, and consists of both numeric and categorical variables."],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["dataset = spark.table(\"lol_red_and_blue_csv\")\n\n\ncols = dataset.columns\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["display(dataset)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["type(dataset)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["import pandas as pd\npandas_df = pd.read_csv(\"/dbfs//FileStore/tables/lol_red_and_blue.csv\" )\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["pandas_df"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["pandas_df['TeamColor'] = pandas_df['TeamColor'].replace({'red':0, 'blue':1})\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["pandas_df"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["type(pandas_df)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["dataset.printSchema()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["###One-Hot Encoding\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = [\"TeamColor\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"Result\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["dataset.columns"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Transform all features into a vector using VectorAssembler\nnumericCols = [\"gamelength\", \"DragonValue\", \"BaronValue\",\"Herald\",\"InhibitsValue\", \"TowerValue\",\"GoldIn10\",\"GoldIn20\",\n \"kill\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(dataset)\ndataset = pipelineModel.transform(dataset)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ndataset = dataset.select(selectedcols)\ndisplay(dataset)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["dataset.printSchema"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["display(dataset)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["display(trainingData)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Logistic regression\nfrom pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# Make predictions on test data using the transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["evaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["print lr.explainParams()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# this will likely take a fair amount of time because of the amount of models that we're creating and testing"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["print 'Model Intercept: ', cvModel.bestModel.intercept"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["#weights = cvModel.bestModel.weights\n# on Spark 2.X weights are available as ceofficients\nweights = cvModel.bestModel.coefficients\nweights = map(lambda w: (float(w),), weights)  # convert numpy type to float, and to tuple\nweightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\ndisplay(weightsDF)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["selected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["print \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"TeamColor\", \"TeamTag\",\"Result\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["dt.getImpurity()"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,6,10])\n             .addGrid(dt.maxBins, [20,40,80])\n             .build())"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# Takes ~5 minutes"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["print \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"TeamColor\", \"TeamTag\",\"Result\")\ndisplay(selected)\n"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = rfModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"TeamColor\", \"TeamTag\",\"Result\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["bestModel = cvModel.bestModel"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["# Generate predictions for entire dataset\nfinalPredictions = bestModel.transform(dataset)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["# Evaluate best model\nevaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["finalPredictions.createOrReplaceTempView(\"finalPredictions\")"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["%sql\nSELECT *\nFROM finalPredictions\n"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["dataset_2 = spark.table(\"deathvalue_including_victim_csv\")\ndisplay(dataset_2)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["#vertices_1 = dataset_2.select(\"Name\")\nvertices_1=dataset_2.select('Victim').distinct()\n#display(vertices_1)\n#vertices_1.count()\n#dataset_2.count()\n#vertice_1 = dataset_2.select(\"Victim\")\ndisplay(vertices_1)"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["vertices_2=dataset_2.select('Name').distinct()"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["td1_2 = vertices_1.unionAll(vertices_2) \nallPerson = td1_2.distinct()\n\n"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["display(dataset_2)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["from pyspark.sql.functions import *\n\nallPerson = allPerson.select(col(\"Victim\").alias(\"id\"))\n\n"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["allRelation = dataset_2.select(\"Name\",\"Victim\",\"Character\")\nallRelation = dataset_2.select(col(\"Name\").alias(\"src\"), col(\"Victim\").alias(\"dst\"),col(\"Character\").alias(\"relationship\"))\nallRelation"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["from graphframes import *\ng = GraphFrame(allPerson, allRelation)\n"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["display(g.vertices)\n"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["display(g.edges)"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["display(g.inDegrees)"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["display(g.outDegrees)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["display(g.degrees)"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["#Count for how many times, the player of 'Cop' kill some one \nnumFollows = g.edges.filter(\"src = 'Cop' and relationship = 'Killer'\").count()\nprint \"The number of follow edges is\", numFollows"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["help(g.find)"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["filteredPaths = g.bfs(\n  fromExpr = \"id = 'Bjergsen'\",\n  toExpr = \"id = 'Hai'\",\n  edgeFilter = \"relationship = 'Killer'\",\n   maxPathLength = 3)\ndisplay(filteredPaths)"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["result = g.stronglyConnectedComponents(maxIter=10)\ndisplay(result.select(\"id\"))"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["results = g.pageRank(resetProbability=0.15, tol=0.01)\ndisplay(results.vertices)"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["display(results.edges)"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["# Run PageRank for a fixed number of iterations.\ng.pageRank(resetProbability=0.15, maxIter=10)"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["# Run PageRank personalized for vertex \"a\"\ng.pageRank(resetProbability=0.15, maxIter=10, sourceId=\"a\")"],"metadata":{},"outputs":[],"execution_count":83}],"metadata":{"name":"HOMEWORK4","notebookId":176425294930727},"nbformat":4,"nbformat_minor":0}
